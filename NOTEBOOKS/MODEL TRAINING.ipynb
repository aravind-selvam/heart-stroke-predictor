{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8f6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44783191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cleaned_stroke.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf1121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X = df.drop(['stroke'], axis=1)\n",
    "y = df['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52c03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variable encoding\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "transform_features = [\"avg_glucose_level\", \"bmi\"]\n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "]\n",
    ")\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one_hot_encoder', OneHotEncoder()),\n",
    "    ('scaler', StandardScaler(with_mean=False))\n",
    "]\n",
    ")\n",
    "\n",
    "transform_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('transformer', PowerTransformer())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, num_features),\n",
    "    ('cat_pipeline', cat_pipeline, cat_features),\n",
    "    ('power_transformer', transform_pipe, transform_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5dbe309",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5c8a6",
   "metadata": {},
   "source": [
    "## Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5df191b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stroke: 249, No Stroke: 4861\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = df[df.stroke==1].shape[0]\n",
    "neg = df[df.stroke==0].shape[0]\n",
    "print(\"Stroke: \" + str(pos) + \", No Stroke: \" + str(neg))\n",
    "sns.catplot(data=df, x=\"stroke\", kind=\"count\", palette=\"winter_r\", alpha=.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec48f4",
   "metadata": {},
   "source": [
    "## Handling Imbalanced Dataset\n",
    "### Handling Imbalanced Target Variable.\n",
    "- Synthetic Minority Oversampling Technique or SMOTE is another technique to oversample the minority class. Simply adding duplicate records of minority class often donâ€™t add any new information to the model.\n",
    "\n",
    "- SMOTE is one of the famous oversampling techniques and is very effective in handling class imbalance. The idea is to combine - SMOTE with some undersampling techniques (ENN, Tomek) to increase the effectiveness of handling the imbalanced class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6c6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTEENN(random_state=42,sampling_strategy='minority' )\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ce483",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "- The train-test split procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model.\n",
    "\n",
    "- It is a fast and easy procedure to perform, the results of which allow you to compare the performance of machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35657ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6736, 23), (1684, 23))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec84359",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "- Here should understand the Various Classification models with default values from these models we can choose top 4 with Highest Accuracy score and proceed with HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4088012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(true, predicted):\n",
    "    acc = accuracy_score(true, predicted) # Calculate Accuracy\n",
    "    f1 = f1_score(true, predicted) # Calculate F1-score\n",
    "    precision = precision_score(true, predicted) # Calculate Precision\n",
    "    recall = recall_score(true, predicted)  # Calculate Recall\n",
    "    roc_auc = roc_auc_score(true, predicted) #Calculate Roc\n",
    "    return acc, f1 , precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9725241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cl(true, predict):\n",
    "    acc = accuracy_score(true, predicted)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4042ba8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9703\n",
      "- F1 score: 0.9729\n",
      "- Precision: 0.9574\n",
      "- Recall: 0.9890\n",
      "- Roc Auc Score: 0.9687\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9210\n",
      "- F1 score: 0.9274\n",
      "- Precision: 0.9208\n",
      "- Recall: 0.9340\n",
      "- Roc Auc Score: 0.9199\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9314\n",
      "- F1 score: 0.9366\n",
      "- Precision: 0.9148\n",
      "- Recall: 0.9595\n",
      "- Roc Auc Score: 0.9297\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9151\n",
      "- F1 score: 0.9227\n",
      "- Precision: 0.9074\n",
      "- Recall: 0.9384\n",
      "- Roc Auc Score: 0.9131\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8472\n",
      "- F1 score: 0.8598\n",
      "- Precision: 0.8346\n",
      "- Recall: 0.8865\n",
      "- Roc Auc Score: 0.8449\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8420\n",
      "- F1 score: 0.8573\n",
      "- Precision: 0.8366\n",
      "- Recall: 0.8790\n",
      "- Roc Auc Score: 0.8388\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9822\n",
      "- F1 score: 0.9834\n",
      "- Precision: 0.9689\n",
      "- Recall: 0.9983\n",
      "- Roc Auc Score: 0.9812\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9656\n",
      "- F1 score: 0.9690\n",
      "- Precision: 0.9428\n",
      "- Recall: 0.9967\n",
      "- Roc Auc Score: 0.9629\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9997\n",
      "- F1 score: 0.9997\n",
      "- Precision: 0.9997\n",
      "- Recall: 0.9997\n",
      "- Roc Auc Score: 0.9997\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9662\n",
      "- F1 score: 0.9689\n",
      "- Precision: 0.9610\n",
      "- Recall: 0.9769\n",
      "- Roc Auc Score: 0.9652\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9914\n",
      "- F1 score: 0.9919\n",
      "- Precision: 0.9880\n",
      "- Recall: 0.9958\n",
      "- Roc Auc Score: 0.9911\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9596\n",
      "- F1 score: 0.9631\n",
      "- Precision: 0.9507\n",
      "- Recall: 0.9758\n",
      "- Roc Auc Score: 0.9582\n",
      "===================================\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9400\n",
      "- F1 score: 0.9447\n",
      "- Precision: 0.9210\n",
      "- Recall: 0.9696\n",
      "- Roc Auc Score: 0.9383\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9240\n",
      "- F1 score: 0.9317\n",
      "- Precision: 0.9047\n",
      "- Recall: 0.9604\n",
      "- Roc Auc Score: 0.9208\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8846\n",
      "- F1 score: 0.8942\n",
      "- Precision: 0.8676\n",
      "- Recall: 0.9224\n",
      "- Roc Auc Score: 0.8824\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8729\n",
      "- F1 score: 0.8852\n",
      "- Precision: 0.8639\n",
      "- Recall: 0.9076\n",
      "- Roc Auc Score: 0.8699\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "     \"Support Vector Classifier\": SVC(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "accuracy_list=[]\n",
    "models_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "    model_train_recall,model_train_rocauc_score=evaluate_clf(y_train ,y_train_pred) \n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "    model_test_recall,model_test_rocauc_score=evaluate_clf(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    models_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "    \n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "    accuracy_list.append(model_test_accuracy)\n",
    "\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df76685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.970309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.966152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>0.965558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>0.959620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.923990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.921021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.915083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.872922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.842043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Name  Accuracy_score\n",
       "0              Random Forest        0.970309\n",
       "5              XGBClassifier        0.966152\n",
       "4     K-Neighbors Classifier        0.965558\n",
       "6     CatBoosting Classifier        0.959620\n",
       "7  Support Vector Classifier        0.923990\n",
       "1              Decision Tree        0.921021\n",
       "2          Gradient Boosting        0.915083\n",
       "8        AdaBoost Classifier        0.872922\n",
       "3        Logistic Regression        0.842043"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results = pd.DataFrame(list(zip(models_list, accuracy_list)), columns=['Model Name', 'Accuracy_score'])\n",
    "Results.sort_values(by=[\"Accuracy_score\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63d54de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize few parameter for Hyperparamter tuning\n",
    "knn_params = {\"n_neighbors\": [2, 3, 10, 20, 40, 50]}\n",
    "\n",
    "rf_params = {\"max_depth\": [5, 8, 15, None, 10],\n",
    "             \"max_features\": [5, 7, \"auto\", 8],\n",
    "             \"min_samples_split\": [2, 8, 15, 20],\n",
    "             \"n_estimators\": [100, 200, 500, 1000]}\n",
    "\n",
    "xgboost_params = {\"learning_rate\": [0.1, 0.01],\n",
    "                  \"max_depth\": [5, 8, 12, 20, 30],\n",
    "                  \"n_estimators\": [100, 200, 300],\n",
    "                  \"colsample_bytree\": [0.5, 0.8, 1, 0.3, 0.4]}\n",
    "\n",
    "cat_params = {\"learning_rate\": [0.1, 0.01],\n",
    "              \"max_depth\": [5, 8, 12, 20, 30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bff319e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models list for Hyperparameter tuning\n",
    "randomcv_models = [('KNN', KNeighborsClassifier(), knn_params),\n",
    "                   (\"RF\", RandomForestClassifier(), rf_params),\n",
    "                   ('XGBoost', XGBClassifier(), xgboost_params),\n",
    "                   ('CatBoost', CatBoostClassifier(verbose=False), cat_params)\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8efd0ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "---------------- Best Params for KNN -------------------\n",
      "{'n_neighbors': 2}\n",
      "---------------- Best Params for RF -------------------\n",
      "{'n_estimators': 1000, 'min_samples_split': 2, 'max_features': 'auto', 'max_depth': None}\n",
      "---------------- Best Params for XGBoost -------------------\n",
      "{'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "---------------- Best Params for CatBoost -------------------\n",
      "{'max_depth': 12, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_param = {}\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator=model,\n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=100,\n",
    "                                   cv=3,\n",
    "                                   verbose=2,\n",
    "                                   n_jobs=-1)\n",
    "    random.fit(X_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"---------------- Best Params for {model_name} -------------------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10d1fe0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9721\n",
      "- F1 score: 0.9746\n",
      "- Precision: 0.9566\n",
      "- Recall: 0.9934\n",
      "- Roc Auc Score: 0.9702\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9993\n",
      "- F1 score: 0.9993\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9986\n",
      "- Roc Auc Score: 0.9993\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9952\n",
      "- F1 score: 0.9956\n",
      "- Precision: 0.9923\n",
      "- Recall: 0.9989\n",
      "- Roc Auc Score: 0.9949\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9709\n",
      "- F1 score: 0.9732\n",
      "- Precision: 0.9664\n",
      "- Recall: 0.9802\n",
      "- Roc Auc Score: 0.9701\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9852\n",
      "- F1 score: 0.9864\n",
      "- Precision: 0.9732\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.9839\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(**model_param['RF']),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(**model_param['KNN']),\n",
    "    \"XGBClassifier\": XGBClassifier(**model_param['XGBoost']), \n",
    "    \"CatBoosting Classifier\": CatBoostClassifier(**model_param['CatBoost'], verbose=False),\n",
    "}\n",
    "\n",
    "accuracy_list=[]\n",
    "models_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "    model_train_recall,model_train_rocauc_score=evaluate_clf(y_train ,y_train_pred) \n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "    model_test_recall,model_test_rocauc_score=evaluate_clf(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    models_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "    accuracy_list.append(model_test_accuracy)\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae33e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>0.995249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>0.985154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.972090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.970903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name  Accuracy_score\n",
       "1  K-Neighbors Classifier        0.995249\n",
       "3  CatBoosting Classifier        0.985154\n",
       "0           Random Forest        0.972090\n",
       "2           XGBClassifier        0.970903"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_retrain = pd.DataFrame(list(zip(models_list, accuracy_list)), columns=['Model Name', 'Accuracy_score'])\n",
    "Results_retrain.sort_values(by=[\"Accuracy_score\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "028556ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "- cross_validation_score: 97.7672\n",
      "K-Neighbors Classifier\n",
      "- cross_validation_score: 99.5606\n",
      "XGBClassifier\n",
      "- cross_validation_score: 97.8979\n",
      "CatBoosting Classifier\n",
      "- cross_validation_score: 98.3848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(**model_param['RF']),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(**model_param['KNN']),\n",
    "    \"XGBClassifier\": XGBClassifier(**model_param['XGBoost']), \n",
    "    \"CatBoosting Classifier\": CatBoostClassifier(**model_param['CatBoost'], verbose=False),\n",
    "}\n",
    "\n",
    "skfold = StratifiedKFold(n_splits= 10,shuffle= True,random_state= 42)\n",
    "\n",
    "accuracy_list=[]\n",
    "models_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    cv_results = cross_val_score(model, X_res, y_res, cv=skfold,scoring=\"accuracy\",n_jobs=-1)\n",
    "    \n",
    "    cross_validation_score = cv_result  s.mean()*100\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    models_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print(\"- cross_validation_score: {:.4f}\".format(cross_validation_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8aba0",
   "metadata": {},
   "source": [
    "### KNN can be used in the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbfe0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe5057b33890e8dd303e21b19623a3798ffaa8a05dcdf7dd3a35472e2b83b2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
